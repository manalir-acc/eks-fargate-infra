name: "Terraform Deployment for EKS"
on:
  # Manual trigger
  workflow_dispatch:
  push:
    paths:
      - '*/**'
  pull_request:
    branches: [ master ]
defaults:
  run:
    shell: bash
    working-directory: ./eks-infra
jobs:
  terraform-infra:
    name:   ${{matrix.runner}} - ${{ matrix.environment }}
    runs-on: [ '${{ matrix.runner }}']
    strategy:
      max-parallel: 1
      matrix:
         include:
           - environment: test
             runner: ubuntu-latest
    env:
         AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
         AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
         AWS_TOKEN: ${{ secrets.AWS_TOKEN }}
         AWS_DEFAULT_REGION: eu-west-1
         AWS_EKS_CLUSTER_NAME: acn-eks-clstr-testing
    steps:
      - uses: actions/checkout@v2
      - name: Install kubectl
        uses: azure/setup-kubectl@v1
        with:
          version: 'v1.22.10'
        id: install
      - uses: actions/checkout@v2
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_TOKEN }}
          aws-region: eu-west-1
      - uses: hashicorp/setup-terraform@v1
        with:
          terraform_wrapper: false
      - name: Terraform Init
        id: init
        run: |
           rm -rf .terraform
           terraform init
      - name: EKS cluster Kubectl config update
        run: |
            echo "Creating Kubectl folder structure and file...."
            mkdir /home/runner/.kube/
            touch /home/runner/.kube/config
            chmod -R 777 /home/runner/.kube/
            echo "Finding existing EKS cluster...." 
            VAR_EKS_CLUSTER_NAME=$(aws eks list-clusters --region ${AWS_DEFAULT_REGION} --query clusters[0] --output text)
            echo "EKS Cluster found: "$VAR_EKS_CLUSTER_NAME
            if [ "$AWS_EKS_CLUSTER_NAME" == "$VAR_EKS_CLUSTER_NAME" ];
            then
             echo "EKS cluster found and setting Kubectl config...." 
             aws eks update-kubeconfig --region ${AWS_DEFAULT_REGION} --name ${AWS_EKS_CLUSTER_NAME}
            else
              echo "EKS Cluster: ${AWS_EKS_CLUSTER_NAME} is not present in ${AWS_DEFAULT_REGION}"
            fi
            ls -lart /home/runner/.kube/
            cat /home/runner/.kube/config
      - name: Terraform Plan
        #if: always()
        if: "!contains(github.event.head_commit.message, 'destroy')"
        id: plan
        run: TF_LOG=DEBUG terraform plan -input=false -var-file=${{ matrix.environment }}/terraform.tfvars -no-color
      - name: Terraform apply
        #if: always()
       # if: github.ref == 'refs/heads/master'
        if: "!contains(github.event.head_commit.message, 'destroy')"
        id: apply
        run: TF_LOG=DEBUG terraform apply -auto-approve -input=false -var-file=${{matrix.environment }}/terraform.tfvars
      - name: Terraform Destroy
        #if: github.ref == 'refs/heads/master'
        if: "contains(github.event.head_commit.message, 'destroy')"
        id: destroy
        run: terraform destroy -auto-approve -input=false -var-file=${{ matrix.environment }}/terraform.tfvars
        
#      - name: adding config file to s3
#        run: |
#          cd /home/runner/.kube
#          chmod -R 755 /home/runner/.kube
#          aws s3 cp --recursive /home/runner/.kube/ s3://landg-terraform-state/eks/configfile/ --region "eu-west-2"
#          ls -lart
#          cat config-custom.cfg
